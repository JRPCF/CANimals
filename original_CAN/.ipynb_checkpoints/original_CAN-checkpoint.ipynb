{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "implementation of original discriminator\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "J.R. Carneiro JC4896\n",
    "\"\"\"\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        v=256*256*3\n",
    "        n=int(((v-4*4+2)/2+1)*32) #((input_volumeâˆ’kernel_volume+2padding)/stride+1)*numberOfLayers\n",
    "        \n",
    "        self.conv1 = self.conv(v, n, 4, 2,1) #(32 4x4)\n",
    "        self.conv2 = self.conv(n,2*n) #(64 4x4)\n",
    "        self.conv3 = self.conv(2*n, 4*n) #(128 4x4)\n",
    "        self.conv4 = self.conv(4*n, 8*n) #(256 4x4)\n",
    "        self.conv5 = self.conv(8*n, 16*n) #(512 4x4)\n",
    "        self.conv6 = self.conv(16*n, 16*n) #(512 4x4)\n",
    "        \n",
    "        self.multi1 = nn.Linear(16*n, 1024)\n",
    "        self.multi2 = nn.Linear(1024, 512)\n",
    "        self.multi3 = nn.Linear(512, num_classes)\n",
    "        \n",
    "        self.real = nn.Linear(16*n, 2)\n",
    "\n",
    "    #helper method to create convolutional layers\n",
    "    def conv(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1):\n",
    "        return nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu((self.conv1(x)), 0.1)\n",
    "        out = F.leaky_relu((self.conv2(out)), 0.1)\n",
    "        out = F.leaky_relu((self.conv3(out)), 0.1)\n",
    "        out = F.leaky_relu((self.conv4(out)), 0.1)\n",
    "        out = F.leaky_relu((self.conv5(out)), 0.1)\n",
    "        out = F.leaky_relu((self.conv6(out)), 0.1)\n",
    "        \n",
    "        out.flatten()\n",
    "        \n",
    "        multi_output = self.multi1(out)\n",
    "        multi_output = self.multi2(multi_output)\n",
    "        multi_output = self.multi3(multi_output)\n",
    "        multi_output = F.softmax(multi_output)\n",
    "        \n",
    "        real_output = self.real(out)\n",
    "        real_output = self.sigmoid(real_output)\n",
    "        \n",
    "        return real_output, multi_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "implementation of original generator\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "J.R. Carneiro JC4896\n",
    "\"\"\"\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        conv_dim = 256*256*3\n",
    "        \n",
    "        self.fc = nn.Linear(100, conv_dim*2*2*2*2*2*2*2)\n",
    "        \n",
    "        self.t_conv1 = self.deconv(conv_dim*2*2*2*2*2*2*2, conv_dim*2*2*2*2*2*2)\n",
    "        self.t_conv2 = self.deconv(conv_dim*2*2*2*2*2*2, conv_dim*2*2*2*2*2)\n",
    "        self.t_conv3 = self.deconv(conv_dim*2*2*2*2*2, conv_dim*2*2*2*2)\n",
    "        self.t_conv4 = self.deconv(conv_dim*2*2*2*2, conv_dim*2*2*2)\n",
    "        self.t_conv5 = self.deconv(conv_dim*2*2*2, conv_dim*2*2)\n",
    "        self.t_conv6 = self.deconv(conv_dim*2*2, conv_dim*2)\n",
    "        self.t_conv7 = self.deconv(conv_dim*2, conv_dim)\n",
    "        \n",
    "    #helper method to create deconvolutional layers\n",
    "    def deconv(self,in_channels, out_channels, kernel_size=4, stride=2, padding=1):\n",
    "        return nn.ConvTranspose2d(in_channels, out_channels,kernel_size,stride,padding, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        out = out.view(-1, 2048) \n",
    "        \n",
    "        out = F.leaky_relu(t_conv1(out),0.1)\n",
    "        out = F.leaky_relu(t_conv2(out),0.1)\n",
    "        out = F.leaky_relu(t_conv3(out),0.1)\n",
    "        out = F.leaky_relu(t_conv4(out),0.1)\n",
    "        out = F.leaky_relu(t_conv5(out),0.1)\n",
    "        out = F.leaky_relu(t_conv6(out),0.1)\n",
    "        out = F.leaky_relu(t_conv7(out),0.1)\n",
    "        \n",
    "        out = F.tanh(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "FROM Udacity DCGAN implementation\n",
    "\"\"\"\n",
    "def real_loss(D_out, smooth=False):\n",
    "    batch_size = D_out.size(0)\n",
    "    # label smoothing\n",
    "    if smooth:\n",
    "        # smooth, real labels = 0.9\n",
    "        labels = torch.ones(batch_size)*0.9\n",
    "    else:\n",
    "        labels = torch.ones(batch_size) # real labels = 1\n",
    "    # move labels to GPU if available     \n",
    "    if train_on_gpu:\n",
    "        labels = labels.cuda()\n",
    "    # binary cross entropy with logits loss\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    # calculate loss\n",
    "    loss = criterion(D_out.squeeze(), labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MODIFIED Udacity DCGAN implementation\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "J.R. Carneiro JC4896\n",
    "\"\"\"\n",
    "def multi_loss(D_out):\n",
    "    batch_size = D_out.size(0)\n",
    "    labels = torch.zeros(batch_size) # fake labels = 0\n",
    "    if train_on_gpu:\n",
    "        labels = labels.cuda()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss = criterion(D_out.squeeze(), labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_loss(D_out):\n",
    "    ### TO BE COMPLETED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "FROM Udacity DCGAN implementation\n",
    "\"\"\"\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if train_on_gpu:\n",
    "    G.cuda()\n",
    "    D.cuda()\n",
    "    print('GPU available for training. Models moved to GPU')\n",
    "else:\n",
    "    print('Training on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MODIFIED Udacity DCGAN implementation\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "J.R. Carneiro JC4896\n",
    "\"\"\"\n",
    "num_epochs = 50\n",
    "\n",
    "# keep track of loss and generated, \"fake\" samples\n",
    "samples = []\n",
    "losses = []\n",
    "print_every = 300\n",
    "sample_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "J.R. Carneiro JC4896\n",
    "\"\"\"\n",
    "# to collect samples from the generator\n",
    "fixed_z = torch.from_numpy(np.random.uniform(-1, 1, size=(sample_size, 100))).float()\n",
    "\n",
    "# 2.\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for batch_i, (real_images, _) in enumerate(train_loader):\n",
    "                \n",
    "        batch_size = real_images.size(0)\n",
    "        \n",
    "        # important rescaling step\n",
    "        #real_images = scale(real_images)\n",
    "        \n",
    "        g_optimizer.zero_grad()\n",
    "        \n",
    "        # 3.\n",
    "        z = np.random.uniform(-1, 1, size=(batch_size, z_size)) \n",
    "        z = torch.from_numpy(z).float()\n",
    "        if train_on_gpu:\n",
    "            z = z.cuda()\n",
    "            \n",
    "        # 4.\n",
    "        fake_images = G(z)\n",
    "        d_optimizer.zero_grad()\n",
    "        \n",
    "        if train_on_gpu:\n",
    "            real_images = real_images.cuda()\n",
    "        \n",
    "        # 5.\n",
    "        D_real, D_multi = D(real_images)\n",
    "        d_real_real_loss = real_loss(D_real) \n",
    "        # 6.\n",
    "        d_real_multi_loss = multi_loss(D_multi)\n",
    "        # 7.\n",
    "        D_fake = D(fake_images)\n",
    "        d_fake_real_loss = real_loss(D_fake)\n",
    "        # 8.\n",
    "        g_fake_entropy_loss = entropy_loss(D_fake) ##\n",
    "        \n",
    "        # 9.\n",
    "        d_loss= log(d_real_real_loss)+log(d_real_multi_loss)+log(1-d_fake_real_loss)\n",
    "        \n",
    "        # 10.\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # 11.\n",
    "        g_loss=log(d_fake_real_loss)-g_fake_entropy_loss\n",
    "        \n",
    "        # 12.\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        \n",
    "### START - FROM Udacity DCGAN implementation ###\n",
    "        # Print some loss stats\n",
    "        if batch_i % print_every == 0:\n",
    "            # append discriminator loss and generator loss\n",
    "            losses.append((d_loss.item(), g_loss.item()))\n",
    "            # print discriminator and generator loss\n",
    "            print('Epoch [{:5d}/{:5d}] | d_loss: {:6.4f} | g_loss: {:6.4f}'.format(\n",
    "                    epoch+1, num_epochs, d_loss.item(), g_loss.item()))\n",
    "\n",
    "    \n",
    "    ## AFTER EACH EPOCH##    \n",
    "    # generate and save sample, fake images\n",
    "    G.eval() # for generating samples\n",
    "    if train_on_gpu:\n",
    "        fixed_z = fixed_z.cuda()\n",
    "    samples_z = G(fixed_z)\n",
    "    samples.append(samples_z)\n",
    "    G.train() # back to training mode\n",
    "\n",
    "# Save training generator samples\n",
    "with open('train_samples.pkl', 'wb') as f:\n",
    "    pkl.dump(samples, f)\n",
    "    \n",
    "### END -   FROM Udacity DCGAN implementation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
